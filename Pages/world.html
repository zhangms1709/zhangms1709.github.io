<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset='UTF-8'>
    <meta name='viewport' content='width=device-width initial-scale=1'>
    <link rel="stylesheet" href="../style.css" type="text/css" />
    <link rel="shortcut icon"
        href="https://cdn.glitch.com/0bbec082-7d40-4980-a895-a6a1b6e627ab%2FScreen%20Shot%202563-12-30%20at%201.32.15%20PM.ico?v=1609353311347" />
    <title>On the creation of digital worlds (6/21)</title>
    <style type="text/css">
        body {
            z-index: -10;
            -webkit-background-size: cover;
            -moz-background-size: cover;
            -o-background-size: cover;
            background-size: auto;
            text-align: left;
            margin: 0;
            padding: 0;
        }

        p {
            text-indent: 50px;
        }

        .content {
            width: 60%;
            margin: 0 auto;
            font-family: 'Verdana', sans-serif;
            padding: 20px;
        }

        .topnav {
            background-color: transparent;
            overflow: hidden;
            font-family: 'Courier New', Courier, monospace !important;
        }

        h2 {
            text-align: center;
        }
    </style>
    <script src="https://unpkg.com/typed.js@2.0.16/dist/typed.umd.js"></script>
</head>

<body>
    <div class="topnav">
        <a href="../index.html">Home</a>
        <a href="portfolio.html">Portfolio</a>
        <a href="quotes.html">Quotes</a>
        <a href="blog.html">Blog</a>
        <!-- <a href="about.html">About</a> -->
    </div>

    <div id='write' class='portfolio'>
        <div class="content">
            <h2><span id="element"></span></h2>

            <script>
                document.addEventListener('DOMContentLoaded', function () {
                    var typed = new Typed('#element', {
                        strings: ["On the creation of digital worlds (6/21)"],
                        typeSpeed: 50,
                    });
                });
            </script>
            <div style="text-align: left;">
                <p style="font-family: Verdana">Recently, autonomous vehicles have been making headlines for all the
                    wrong reasons, robotaxis in San Francisco hitting cyclists and dragging pedestrians. With the
                    massive strides AI has been making in the past few years, the question is begged: why hasn’t any
                    safe fully self-driving car been developed yet?
                </p>

                <p style="font-family: Verdana"> Here’s the main issue: the world cannot be contained in a dataset.
                    These cars, as other forms of AI, are trained on data. We can try to make that data as comprehensive
                    as possible, but it will always fall short compared to the many layers of complexity and unexpected
                    randomness of the real world, so-called anti-patterns which models cannot pick up on if all they can
                    do is pick up on patterns in the data.
                </p>

                <p style="font-family: Verdana">The interesting ethical question to be asked is should we create digital
                    worlds? Here, I assume that this implies that one is seeking to reduce the world to a dataset?
                    Reductionism posits at its core that instead of listing all the facts of the world, we just need to
                    list the fundamental few. In other words, all God had to do to create the world was create the
                    fundamental facts (everything else builds up from there). This is the task of reductionism broadly
                    construed.
                </p>

                <p style="font-family: Verdana">Here I provide arguments for why we should and should not create
                    reductive digital worlds. Of course, any representation of the world is reductive. There is,
                    however, more reductive versus less reductive versions. Here, I mean reduce in the sense of actively
                    excluding information and trying to simplify complex information.
                </p>

                <p style="font-family: Verdana">Take the adjacent example of AI imaging. Image data provides enormous
                    complexity, and thus some models have been trained which are better than radiologists at identifying
                    tumors from images of human tissue slices. In that sense, a high resolution image is less reductive
                    than a fuzzier image. Yet, in many other real world applications of models, features are often
                    handpicked (known as feature selection or feature engineering) to facilitate the best results.
                </p>

                <p style="font-family: Verdana">As to any conclusions on the ethical question I posed above, I will let
                    the reader decide! Below, I list potential reasons for and against reducing the world, and by
                    extension, building digital worlds such as the Metaverse. I start with the reasons to support.
                </p>

                <p style="font-family: Verdana">How else would one encapsulate the world? Human perception is also
                    reductive. When we see something, we cannot see everything. Our attention focuses on a few select
                    things. Thus, what we see is a reduced representation. Notably, 1) it is sufficient for us to
                    survive and 2) to expect something other than reduction in tasks ranging from building digital
                    worlds to training AI would be an impractical standard.
                </p>

                <p style="font-family: Verdana">Another argument for reduction is by looking at the current state of
                    technology. Through these rapid developments, many fields, such as biology, have been able to make
                    significant advancements in research and advancing human knowledge. Reduction is proven to work and
                    has displayed promising results. We thus can reasonably expect that building digital worlds might be
                    fruitful as well.
                </p>

                <p style="font-family: Verdana">But, there are also reasons for us to shun reduction. The most
                    straightforward is that reduction marginalizes. Amazon’s hiring algorithms systematically
                    discriminated against women although its data did not explicitly consider gender. Since AI is
                    trained on past data, it is also stuck in the past and bound to repeat the systematic patterns of
                    discrimination which the data reflects. By reducing even further, we risk losing important nuances
                    and committing past errors. In a data world, there is nothing new or novel. Imitation of the past is
                    cleverly disguised as the future.
                </p>

                <p style="font-family: Verdana">On the matter of imitating the world through data, it’s clear that any
                    reproduction would be second rate. It’s hard to make a world which feels as real as our world. And
                    even if a world was able to be created out of data, it would be subject to imperfections and like
                    any dataset, it is limited and fragile (i.e. prone to data corruption or glitches). There is no such
                    thing as an infinite dataset, but there is that sense of limitlessness in our world.
                </p>

                <p style="font-family: Verdana">There are also arguments which can be spun both ways. In creating a
                    world, we get to build it from the ground up. That’s both empowering, if done responsibly, and
                    dangerous otherwise. Worlds are vastly complex systems, and whether reduction is the right approach
                    is still a question left for time, or perhaps it will remain unanswered as do all other forms of
                    utopianism.</p>

                </p>
            </div>
        </div>
    </div>
</body>

</html>